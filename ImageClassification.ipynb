{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python==4.1.0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the output layer names \n",
    "# in the architecture\n",
    "\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "classes = None\n",
    "classes = open('darknet/data/coco.names').read().strip().split('\\n')\n",
    "    \n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "# function to draw bounding box on the detected object with class name\n",
    "def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h,label,noOfcars):\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv2.putText(img, label +\" \"+ str(round(confidence,2)) , (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "#function to add text on image\n",
    "def text_on_image(img, class_id,noOfcars,fps):\n",
    "    color = COLORS[class_id]\n",
    "    cv2.putText(img, \"No:cars in frame: \" +str(noOfcars), (50,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    cv2.putText(img, \"FPS: \" +str(round(fps,2)), (30,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global COLORS\n",
    "# read pre-trained model and config file\n",
    "net = cv2.dnn.readNet('darknet/cfg/yolov3-tiny.cfg', 'darknet/cfg/yolov3-tiny.weights')\n",
    "def detectObject(img,frameNumber):\n",
    "    from keras.preprocessing import image\n",
    "    # read input image\n",
    "    img = img\n",
    "    Width = img.shape[1]\n",
    "    Height = img.shape[0]\n",
    "\n",
    "    scale = 0.00392\n",
    "\n",
    "    # read class names from text file\n",
    "    classes = None\n",
    "    classes = open('darknet/data/coco.names').read().strip().split('\\n')\n",
    "    \n",
    "    # generate different colors for different classes \n",
    "    COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "    # create input blob \n",
    "    blob = cv2.dnn.blobFromImage(img, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "    # set input blob for the network\n",
    "    net.setInput(blob)\n",
    "    # run inference through the network\n",
    "    # and gather predictions from output layers\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "    # initialization\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    # for each detetion from each output layer \n",
    "    # get the confidence, class id, bounding box params\n",
    "    # and ignore weak detections (confidence < 0.5)\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * Width)\n",
    "                center_y = int(detection[1] * Height)\n",
    "                w = int(detection[2] * Width)\n",
    "                h = int(detection[3] * Height)\n",
    "                x = center_x - w / 2\n",
    "                y = center_y - h / 2\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "                \n",
    "\n",
    "\n",
    "    # apply non-max suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    # go through the detections remaining\n",
    "    # after nms and draw bounding box\n",
    "    \n",
    "    suv=0\n",
    "    sedan=0\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        x = box[0]\n",
    "        y = box[1]\n",
    "        w = box[2]\n",
    "        h = box[3]\n",
    "        x = round(x)\n",
    "        y = round(y)\n",
    "        w = round(w)\n",
    "        h = round(h)\n",
    "        cropped = img[x:x+w, y:y+h]\n",
    "        labels={}\n",
    "        labels[0]=\"SEDAN\"\n",
    "        labels[1]=\"SUV\"\n",
    "        img_tensor = image.img_to_array(cropped)                    # (height, width, channels)\n",
    "        img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "        img_tensor /= 255. \n",
    "        tb._SYMBOLIC_SCOPE.value=False\n",
    "        index = np.argmax(model.predict(img_tensor))\n",
    "        draw_bounding_box(img, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h),labels[index],len(indices))\n",
    "        \n",
    "        if labels[index]==\"SEDAN\":\n",
    "            sedan+=1\n",
    "        elif labels[index]==\"SUV\":\n",
    "            suv+=1\n",
    "\n",
    "    # release resources\n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps = frameNumber/elapsed_time\n",
    "    text_on_image(img, 1,len(indices),fps)\n",
    "    \n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return img,sedan,suv,len(indices),round(fps,2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend.tensorflow_backend as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet()\n",
    "def prepare_image(file):\n",
    "    img_path = ''\n",
    "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to check predictions from original Mobilenet model\n",
    "# preprocessed_image = prepare_image('output/frame0.jpg')\n",
    "# predictions = mobile.predict(preprocessed_image)\n",
    "# results = imagenet_utils.decode_predictions(predictions)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(2,activation='sigmoid')(x) #final layer with softmax activation\n",
    "# preds=Dense(2,activation='softmax')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to see layer details in model\n",
    "# for i,layer in enumerate(model.layers):\n",
    "#     print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "# or if we want to set the first 20 layers of the network to be non-trainable\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#importing training images split as train and test, image resized to 224,224 \n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2,preprocessing_function=preprocess_input)\n",
    "X_train = image_generator.flow_from_directory(directory='Images',\n",
    "                                                     batch_size=32,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(224, 224),\n",
    "                                                      subset=\"training\",\n",
    "                                                      class_mode='categorical')\n",
    "label = (X_train.class_indices)\n",
    "print(label)\n",
    "X_test = image_generator.flow_from_directory(directory='Images',\n",
    "                                                     batch_size=32,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     class_mode='categorical',\n",
    "                                                     subset=\"validation\")\n",
    "\n",
    "label_t = (X_test.class_indices)\n",
    "print(label_t)\n",
    "labels={}\n",
    "labels[0]=\"SEDAN\"\n",
    "labels[1]=\"SUV\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "# loss function categorical cross entropy\n",
    "# evaluation metrics accuracy\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average Validation accuracy\n",
    "print(\"Validation Accuracy of Trained model: \",np.mean(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mobileNetv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('mobileNetv1.h5')\n",
    "model = keras.models.load_model('mobileNetv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Condition\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "condition = Condition()\n",
    "queue = []\n",
    "\n",
    "class ConsumerThread(Thread):\n",
    "    def run(self):\n",
    "        global queue\n",
    "        global starting_time\n",
    "        global elapsed_time\n",
    "        i=0\n",
    "        frameNo=[]\n",
    "        carCount=[]\n",
    "        sedan=[]\n",
    "        suv=[]\n",
    "        fps_l=[]\n",
    "        while True:\n",
    "            try:\n",
    "\n",
    "                condition.acquire()\n",
    "                if not queue:\n",
    "                    #print (\"Nothing in queue, consumer is waiting\")\n",
    "                    condition.wait()\n",
    "                    #print (\"Producer added something to queue and notified the consumer\")\n",
    "                img = queue.pop(0)\n",
    "                output,sedanC,suvC,carC,fps=detectObject(img,i)\n",
    "                frameNo.append(i+1)\n",
    "                sedan.append(sedanC)\n",
    "                suv.append(suvC)\n",
    "                carCount.append(carC)\n",
    "                fps_l.append(fps)\n",
    "                cv2.imwrite(\"output/frame%d.jpg\"%i, output)\n",
    "                i+=1\n",
    "                #print (\"Consumed\")\n",
    "                condition.release()\n",
    "                #time.sleep(random.random())\n",
    "            except AttributeError:\n",
    "                break;\n",
    "        elapsed_time = time.time() - starting_time\n",
    "        print(\"Total Pipeline Time: \",elapsed_time)\n",
    "        frame = cv2.imread(\"output/frame0.jpg\")\n",
    "        height, width, layers = frame.shape\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        video_name = 'output.mp4'\n",
    "        video = cv2.VideoWriter(video_name, fourcc, 30.0, (width,height))\n",
    "\n",
    "        for i in range(i+1):\n",
    "            video.write(cv2.imread(\"output/frame%d.jpg\"%i)) \n",
    "        video.release()\n",
    "        list_of_tuples = list(zip(frameNo, sedan,suv,carCount,fps_l))\n",
    "        df = pd.DataFrame(list_of_tuples, \n",
    "                  columns = ['Frame#', 'SEDAN','SUV','Total',\"Output FPS\"])\n",
    "        df.to_csv('output.csv')\n",
    "    \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ProducerThread(Thread):\n",
    "    def run(self):\n",
    "        global queue\n",
    "        vidcap = cv2.VideoCapture('darknet/data/assignment-clip.mp4')\n",
    "        success,img = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "            condition.acquire()     \n",
    "            success,img = vidcap.read()\n",
    "            queue.append(img)\n",
    "            count += 1\n",
    "            #print (\"Produced\")\n",
    "            condition.notify()\n",
    "            condition.release()\n",
    "            time.sleep(0.001)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pipeline Time:  47.138108015060425\n"
     ]
    }
   ],
   "source": [
    "global starting_time\n",
    "\n",
    "#start producer and consumer thread, prints total pipeline time on completion\n",
    "starting_time = time.time()\n",
    "ProducerThread().start()\n",
    "ConsumerThread().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "output=pd.read_csv('output.csv')\n",
    "ytrue=pd.read_csv('groundtruth.csv')\n",
    "\n",
    "#output[\"Total\"]=output.apply(lambda row: row.SEDAN + row.SUV, axis=1)\n",
    "output = output[['Frame#', 'SEDAN', 'SUV','Total','Output FPS']].copy()\n",
    "ytrue.drop(ytrue[ytrue['Frame#'] == 900].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(output['Frame#'],output['Output FPS'])\n",
    "plt.title('Output Rate For Pipeline')\n",
    "plt.xlabel('Frame #')\n",
    "plt.ylabel('OutputFPS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Throughput (in FPS):  18.83\n",
      "Average Time taken to process each frame (in Seconds):  0.053\n"
     ]
    }
   ],
   "source": [
    "#Average throughput in FPS\n",
    "print(\"Average Throughput (in FPS): \",round(output['Output FPS'].mean(),2))\n",
    "\n",
    "#Time taken for each frame\n",
    "print(\"Average Time taken to process each frame (in Seconds): \",round(1/output['Output FPS'].mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating F1 score for Q1\n",
    "#precision is given by TP/(TP+FP)\n",
    "#TP is Total from output file, FP is 0 as we can see from video that there are no incorrect positives\n",
    "#output['Total']/output['Total'] will always be equal to 1 in our case\n",
    "#for Recall is given by TP/(TP+FN) - which will be output['total']/ytrue['total']\n",
    "precision=output['Total']/output['Total']\n",
    "recall=output['Total']/ytrue['Total']\n",
    "#f1=2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean average precision\n",
    "MAP=precision.mean()\n",
    "MAR=recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_objectdetection=2*MAP*MAR/(MAP+MAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for object detection:  0.8372368747238063\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score for object detection: \", f1_objectdetection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 for classification Q2\n",
    "#Assumptions made for calculating TP,FP,FN values\n",
    "#pseudo code\n",
    "# if output == groundtruth\n",
    "#    TP=output\n",
    "#.elseif output>groundtruth\n",
    "#.   TP=groundtruth\n",
    "# else\n",
    "#.   TP=output\n",
    "\n",
    "TPSed=np.where(output['SEDAN']==ytrue['Sedan'], output['SEDAN'], np.where(output['SEDAN']>ytrue['Sedan'],ytrue['Sedan'],output['SEDAN']))\n",
    "TPSUV=np.where(output['SUV']==ytrue['SUV'], output['SUV'], np.where(output['SUV']>ytrue['SUV'],ytrue['SUV'],output['SUV']))\n",
    "\n",
    "\n",
    "# if output == groundtruth\n",
    "#    FP=0\n",
    "#.elseif output>groundtruth\n",
    "#.   FP=output-groundtruth\n",
    "# else\n",
    "#.   FP=0\n",
    "\n",
    "FPSed=np.where(output['SEDAN']==ytrue['Sedan'], 0, np.where(output['SEDAN']>ytrue['Sedan'],output['SEDAN']-ytrue['Sedan'],0))\n",
    "FPSUV=np.where(output['SUV']==ytrue['SUV'], 0, np.where(output['SUV']>ytrue['SUV'],output['SUV']-ytrue['SUV'],0))\n",
    "\n",
    "\n",
    "# if output == groundtruth\n",
    "#    FN=0\n",
    "#.elseif output<groundtruth\n",
    "#.   FN=groundtruth-output\n",
    "# else\n",
    "#.   FN=0\n",
    "\n",
    "FNSed = np.where(output['SEDAN']==ytrue['Sedan'], 0, np.where(output['SEDAN']<ytrue['Sedan'],ytrue['Sedan']-output['SEDAN'],0))\n",
    "FNSUV = np.where(output['SUV']==ytrue['SUV'], 0, np.where(output['SUV']<ytrue['SUV'],ytrue['SUV']-output['SUV'],0))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryavikram/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "precision_q2=(TPSed+TPSUV)/(TPSed+TPSUV+FPSed+FPSUV)\n",
    "recall_q2=(TPSed+TPSUV)/(TPSed+TPSUV+FNSed+FNSUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Mean Average Precision and mean average recall\n",
    "MAP_q2=np.nanmean(precision_q2)\n",
    "MAR_q2=np.nanmean(recall_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_classification=2*MAP_q2*MAR_q2/(MAP_q2+MAR_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Classification:  0.5284187840521777\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score for Classification: \", f1_classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
